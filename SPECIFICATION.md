# Neural Network v2 Specification

This document outlines the specification for version 2.0 of `@am/neuralnetwork`, aiming to transform it from a basic feedforward neural network library into a comprehensive, production-ready deep learning framework while maintaining its core principles of simplicity and cross-runtime compatibility.

## Vision & Goals

### Core Principles (Maintained)

- **Simplicity**: Easy to understand and use API
- **Cross-runtime**: Works in Node.js, Deno, Bun, and browsers
- **Zero dependencies**: Pure TypeScript implementation
- **Educational value**: Clear, readable code that helps users learn

### New Goals for v2

- **Production-ready**: Suitable for real-world applications
- **Extensible**: Plugin architecture for custom layers, losses, and metrics
- **Feature-rich**: Support for modern deep learning architectures
- **Developer-friendly**: Better debugging, visualization, and tooling

## Architecture Changes

### 1. Layer System Refactor

#### New Base Layer Interface

```typescript
interface Layer {
  name: string;
  trainable: boolean;
  
  // Core methods
  build(inputShape: number[]): void;
  forward(input: Tensor, training?: boolean): Tensor;
  backward(gradient: Tensor): Tensor;
  getWeights(): Tensor[];
  setWeights(weights: Tensor[]): void;
  
  // Shape inference
  computeOutputShape(inputShape: number[]): number[];
  
  // Serialization
  getConfig(): Record<string, unknown>;
  
  // Parameter counting
  countParams(): number;
}
```

#### New Layer Types

**Convolutional Layers**
- `Conv1D`: 1D convolution (time series, text)
- `Conv2D`: 2D convolution (images)
- `Conv3D`: 3D convolution (video, volumetric data)
- `DepthwiseConv2D`: Efficient mobile architectures
- `SeparableConv2D`: Depthwise separable convolutions

**Pooling Layers**
- `MaxPooling1D`, `MaxPooling2D`, `MaxPooling3D`
- `AveragePooling1D`, `AveragePooling2D`, `AveragePooling3D`
- `GlobalMaxPooling1D`, `GlobalMaxPooling2D`
- `GlobalAveragePooling1D`, `GlobalAveragePooling2D`

**Recurrent Layers**
- `SimpleRNN`: Basic recurrent layer
- `LSTM`: Long Short-Term Memory
- `GRU`: Gated Recurrent Unit
- `Bidirectional`: Wrapper for bidirectional RNNs

**Regularization Layers**
- `Dropout`: Random dropout for preventing overfitting
- `SpatialDropout1D`, `SpatialDropout2D`: Spatial dropout
- `GaussianNoise`: Add Gaussian noise during training
- `GaussianDropout`: Multiplicative Gaussian noise
- `AlphaDropout`: Self-normalizing dropout for SELU

**Normalization Layers**
- `BatchNormalization`: Batch normalization
- `LayerNormalization`: Layer normalization
- `GroupNormalization`: Group normalization
- `InstanceNormalization`: Instance normalization

**Reshaping Layers**
- `Flatten`: Flatten multi-dimensional input
- `Reshape`: Reshape to specified shape
- `Permute`: Permute dimensions
- `RepeatVector`: Repeat input n times
- `Cropping1D`, `Cropping2D`, `Cropping3D`: Crop dimensions
- `ZeroPadding1D`, `ZeroPadding2D`, `ZeroPadding3D`: Add padding

**Merge Layers**
- `Add`: Element-wise addition
- `Subtract`: Element-wise subtraction
- `Multiply`: Element-wise multiplication
- `Average`: Element-wise averaging
- `Maximum`: Element-wise maximum
- `Minimum`: Element-wise minimum
- `Concatenate`: Concatenate tensors
- `Dot`: Dot product

**Advanced Layers**
- `Embedding`: Embedding layer for discrete inputs
- `Attention`: Self-attention mechanism
- `MultiHeadAttention`: Multi-head attention (Transformers)
- `LayerNormalization`: For transformer architectures

### 2. Tensor System

Introduce a proper `Tensor` class to replace raw number arrays:

```typescript
class Tensor {
  data: Float32Array | Float64Array;
  shape: number[];
  strides: number[];
  
  // Operations
  add(other: Tensor): Tensor;
  subtract(other: Tensor): Tensor;
  multiply(other: Tensor): Tensor;
  divide(other: Tensor): Tensor;
  matmul(other: Tensor): Tensor;
  transpose(axes?: number[]): Tensor;
  reshape(shape: number[]): Tensor;
  
  // Aggregations
  sum(axis?: number | number[], keepDims?: boolean): Tensor;
  mean(axis?: number | number[], keepDims?: boolean): Tensor;
  max(axis?: number | number[], keepDims?: boolean): Tensor;
  min(axis?: number | number[], keepDims?: boolean): Tensor;
  
  // Utilities
  slice(start: number[], end: number[]): Tensor;
  squeeze(axis?: number): Tensor;
  expandDims(axis: number): Tensor;
  
  // Conversion
  toArray(): number[];
  toNestedArray(): number[] | number[][] | number[][][];
}
```

### 3. Enhanced Model API

#### Training Configuration

```typescript
interface FitConfig {
  epochs: number;
  batchSize: number;
  validationData?: [Tensor, Tensor];
  validationSplit?: number;
  shuffle?: boolean;
  verbose?: 0 | 1 | 2; // 0: silent, 1: progress bar, 2: one line per epoch
  callbacks?: Callback[];
  initialEpoch?: number;
  stepsPerEpoch?: number;
  validationSteps?: number;
  classWeight?: Record<number, number>;
  sampleWeight?: Tensor;
}

// Enhanced fit method
await model.fit(
  trainX,
  trainY,
  {
    epochs: 100,
    batchSize: 32,
    validationSplit: 0.2,
    callbacks: [
      new EarlyStopping({ monitor: 'val_loss', patience: 10 }),
      new ModelCheckpoint({ filepath: 'best_model.json', monitor: 'val_loss' }),
      new ReduceLROnPlateau({ monitor: 'val_loss', factor: 0.5, patience: 5 })
    ]
  }
);
```

#### Callbacks System

```typescript
abstract class Callback {
  onEpochBegin?(epoch: number, logs?: Logs): void | Promise<void>;
  onEpochEnd?(epoch: number, logs?: Logs): void | Promise<void>;
  onBatchBegin?(batch: number, logs?: Logs): void | Promise<void>;
  onBatchEnd?(batch: number, logs?: Logs): void | Promise<void>;
  onTrainBegin?(logs?: Logs): void | Promise<void>;
  onTrainEnd?(logs?: Logs): void | Promise<void>;
}

// Built-in callbacks
class EarlyStopping extends Callback
class ModelCheckpoint extends Callback
class ReduceLROnPlateau extends Callback
class LearningRateScheduler extends Callback
class TensorBoard extends Callback
class CSVLogger extends Callback
class ProgbarLogger extends Callback
class LambdaCallback extends Callback
```

#### History Tracking

```typescript
interface History {
  epoch: number[];
  history: {
    loss: number[];
    accuracy?: number[];
    val_loss?: number[];
    val_accuracy?: number[];
    [metric: string]: number[] | undefined;
  };
}

const history = await model.fit(trainX, trainY, config);
console.log(history.history.loss); // [0.5, 0.3, 0.2, ...]
console.log(history.history.val_accuracy); // [0.7, 0.8, 0.85, ...]
```

### 4. Metrics System

```typescript
interface Metric {
  name: string;
  compute(yTrue: Tensor, yPred: Tensor): number;
  reset(): void;
}

// Available metrics
class Accuracy implements Metric
class BinaryAccuracy implements Metric
class CategoricalAccuracy implements Metric
class SparseCategoricalAccuracy implements Metric
class TopKAccuracy implements Metric
class Precision implements Metric
class Recall implements Metric
class F1Score implements Metric
class AUC implements Metric
class MeanSquaredError implements Metric
class MeanAbsoluteError implements Metric
class MeanAbsolutePercentageError implements Metric
class CosineSimilarity implements Metric

// Usage
model.compile(
  optimizer: new Adam(),
  loss: new CategoricalCrossentropy(),
  metrics: [
    new CategoricalAccuracy(),
    new TopKAccuracy(k: 5),
    new Precision(),
    new Recall()
  ]
);
```

### 5. Data Pipeline

```typescript
// Dataset abstraction
class Dataset<T> {
  batch(size: number): Dataset<T[]>;
  shuffle(bufferSize: number): Dataset<T>;
  map<U>(fn: (item: T) => U): Dataset<U>;
  filter(fn: (item: T) => boolean): Dataset<T>;
  take(count: number): Dataset<T>;
  skip(count: number): Dataset<T>;
  repeat(count?: number): Dataset<T>;
  prefetch(bufferSize: number): Dataset<T>;
}

// Data generators
interface DataGenerator {
  [Symbol.asyncIterator](): AsyncIterator<[Tensor, Tensor]>;
  length: number;
}

// Image data augmentation
class ImageDataGenerator implements DataGenerator {
  constructor(config: {
    rotation?: number;
    widthShift?: number;
    heightShift?: number;
    shear?: number;
    zoom?: number;
    horizontalFlip?: boolean;
    verticalFlip?: boolean;
    fillMode?: 'constant' | 'nearest' | 'reflect' | 'wrap';
    brightness?: number;
    preprocessing?: (img: Tensor) => Tensor;
  });
  
  flowFromDirectory(directory: string): DataGenerator;
  flow(X: Tensor, y: Tensor, batchSize: number): DataGenerator;
}

// Usage
const trainGen = new ImageDataGenerator({
  rotation: 20,
  horizontalFlip: true,
  zoom: 0.2
}).flowFromDirectory('./data/train');

await model.fit(trainGen, { epochs: 50 });
```

### 6. Loss Functions (Additions)

```typescript
// Additional loss functions
class KLDivergence extends Loss
class Poisson extends Loss
class CosineProximity extends Loss
class LogCosh extends Loss
class CategoricalHinge extends Loss
class SquaredHinge extends Loss
class SparseCategoricalCrossentropy extends Loss
class Focal extends Loss // For imbalanced datasets
class Dice extends Loss // For segmentation tasks
class Tversky extends Loss // For segmentation tasks
class Jaccard extends Loss // IoU loss
```

### 7. Optimizer Enhancements

```typescript
// Enhanced optimizers with additional features
class Optimizer {
  learningRate: number | LearningRateSchedule;
  clipNorm?: number;
  clipValue?: number;
  
  // Learning rate schedules
  setLearningRate(lr: number | LearningRateSchedule): void;
  getLearningRate(): number;
}

// Learning rate schedules
interface LearningRateSchedule {
  (epoch: number): number;
}

class ExponentialDecay implements LearningRateSchedule
class StepDecay implements LearningRateSchedule
class CosineDecay implements LearningRateSchedule
class CosineDecayRestarts implements LearningRateSchedule
class PolynomialDecay implements LearningRateSchedule

// New optimizers
class AdamW extends Optimizer // Adam with weight decay
class Nadam extends Optimizer // Adam + Nesterov momentum
class Adamax extends Optimizer
class Adadelta extends Optimizer
class Ftrl extends Optimizer
class Lion extends Optimizer // Modern optimizer (2023)
```

### 8. Model Architectures

```typescript
// Functional API for complex architectures
const input = new Input({ shape: [28, 28, 1] });
const x = new Conv2D({ filters: 32, kernelSize: 3, activation: 'relu' }).apply(input);
const x2 = new MaxPooling2D({ poolSize: 2 }).apply(x);
const x3 = new Flatten().apply(x2);
const output = new Dense({ units: 10, activation: 'softmax' }).apply(x3);

const model = new Model({ inputs: input, outputs: output });

// Multi-input, multi-output models
const input1 = new Input({ shape: [64] });
const input2 = new Input({ shape: [32] });
const combined = new Concatenate().apply([input1, input2]);
const dense = new Dense({ units: 16 }).apply(combined);
const output1 = new Dense({ units: 1, name: 'main_output' }).apply(dense);
const output2 = new Dense({ units: 1, name: 'aux_output' }).apply(dense);

const model = new Model({
  inputs: [input1, input2],
  outputs: [output1, output2]
});

// Pre-built architectures
class Sequential extends Model // Keep existing sequential API
class ResNet50 extends Model
class MobileNetV2 extends Model
class EfficientNetB0 extends Model
class VGG16 extends Model
class InceptionV3 extends Model
```

### 9. Model Utilities

```typescript
// Model inspection
model.summary(); // Print model architecture
model.countParams(); // Total parameters
model.layerNames; // List of layer names
model.getLayer(name: string): Layer;

// Weight management
const weights = model.getWeights();
model.setWeights(weights);
model.saveWeights('weights.bin');
model.loadWeights('weights.bin');

// Model freezing
model.freeze(); // Freeze all layers
model.unfreeze(); // Unfreeze all layers
model.getLayer('conv2d_1').trainable = false; // Freeze specific layer

// Model cloning
const clonedModel = model.clone();

// Convert between formats
model.toJSON(); // Export to JSON
Model.fromJSON(json); // Import from JSON
model.toONNX(); // Export to ONNX
Model.fromONNX(onnx); // Import from ONNX (if feasible)
```

### 10. Visualization & Debugging

```typescript
// Model visualization
model.plot({ 
  showShapes: true, 
  showLayerNames: true,
  rankdir: 'TB' // Top to bottom
}); // Returns SVG/Mermaid diagram

// Layer output inspection
const debugModel = new Model({
  inputs: model.inputs,
  outputs: model.getLayer('conv2d_3').output
});
const intermediateOutput = debugModel.predict(input);

// Gradient inspection
const gradients = model.computeGradients(input, output);

// Activation visualization
const activations = model.getActivations(input);
```

### 11. Transfer Learning

```typescript
// Load pre-trained model
const baseModel = await Model.load('mobilenet_v2', {
  weights: 'imagenet',
  includeTop: false,
  inputShape: [224, 224, 3]
});

// Freeze base model
baseModel.freeze();

// Add custom layers
const model = new Sequential();
model.add(baseModel);
model.add(new GlobalAveragePooling2D());
model.add(new Dense({ units: 256, activation: 'relu' }));
model.add(new Dropout(0.5));
model.add(new Dense({ units: numClasses, activation: 'softmax' }));

// Train only new layers
model.compile({ optimizer: new Adam(0.001), loss: new CategoricalCrossentropy() });
await model.fit(trainData, trainLabels, { epochs: 10 });

// Fine-tuning: unfreeze and train with lower learning rate
baseModel.unfreeze();
model.compile({ optimizer: new Adam(0.0001), loss: new CategoricalCrossentropy() });
await model.fit(trainData, trainLabels, { epochs: 10 });
```

### 12. Cross-Validation & Hyperparameter Tuning

```typescript
// K-fold cross-validation
class KFold {
  constructor(nSplits: number, shuffle?: boolean, randomState?: number);
  split(X: Tensor, y: Tensor): Generator<[Tensor, Tensor, Tensor, Tensor]>;
}

const kfold = new KFold(5, true);
const scores: number[] = [];

for (const [trainX, trainY, valX, valY] of kfold.split(X, y)) {
  const model = createModel();
  await model.fit(trainX, trainY, { 
    epochs: 50, 
    validationData: [valX, valY],
    verbose: 0
  });
  const score = model.evaluate(valX, valY);
  scores.push(score.accuracy);
}

console.log(`Average accuracy: ${mean(scores)}`);

// Grid search
class GridSearchCV {
  constructor(
    modelBuilder: (params: Record<string, unknown>) => Model,
    paramGrid: Record<string, unknown[]>,
    cv?: number
  );
  
  async fit(X: Tensor, y: Tensor): Promise<GridSearchResult>;
}

const gridSearch = new GridSearchCV(
  (params) => {
    const model = new Sequential();
    model.add(new Dense({ units: params.units as number, activation: 'relu' }));
    model.add(new Dense({ units: 10, activation: 'softmax' }));
    model.compile({ 
      optimizer: new Adam(params.lr as number), 
      loss: new CategoricalCrossentropy() 
    });
    return model;
  },
  {
    units: [32, 64, 128],
    lr: [0.001, 0.01, 0.1]
  },
  cv: 3
);

const results = await gridSearch.fit(X, y);
console.log(`Best params: ${results.bestParams}`);
console.log(`Best score: ${results.bestScore}`);
```

### 13. Model Interpretability

```typescript
// Gradient-based visualization
class GradCAM {
  constructor(model: Model, layerName: string);
  compute(input: Tensor, classIndex: number): Tensor;
}

// Feature importance
class FeatureImportance {
  constructor(model: Model);
  compute(X: Tensor, y: Tensor, method: 'permutation' | 'shap'): number[];
}

// Saliency maps
class SaliencyMap {
  constructor(model: Model);
  compute(input: Tensor, classIndex: number): Tensor;
}
```

## API Compatibility

### Breaking Changes

- `Model.fit()` signature changes to accept config object instead of positional params
- Input/output changes from `number[][]` to `Tensor`
- Layer constructor APIs standardized to object-based config

### Migration Guide

```typescript
// v1
await model.fit(trainData, trainLabels, 1000, 32, false);

// v2
await model.fit(trainData, trainLabels, {
  epochs: 1000,
  batchSize: 32,
  verbose: 0
});

// v1
model.addLayer(new Dense(10, 20));

// v2
model.add(new Dense({ inputDim: 10, units: 20 }));
// or maintain v1 style as convenience
model.add(new Dense(20, { inputDim: 10 }));
```

## Performance Targets

- **Training speed**: 2-3x faster than v1 with optimized tensor operations
- **Memory usage**: 30% reduction through proper tensor management
- **Model load time**: < 100ms for models up to 10MB
- **Prediction latency**: < 10ms for batch size 1 on typical models

## Testing & Quality

### Test Coverage

- Unit tests: > 90% coverage
- Integration tests for all layer types
- End-to-end tests for common architectures
- Performance benchmarks
- Cross-runtime compatibility tests

### Documentation

- API reference (auto-generated from TypeScript with jsr)
- User guides for all major features
- Migration guide from v1
- Architecture decision records

## Implementation Phases

### Phase 1: Foundation

- [ ] Tensor class implementation
- [ ] Refactor base Layer interface
- [ ] Update existing layers to new interface
- [ ] Basic callbacks system
- [ ] History tracking
- [ ] Enhanced metrics system

### Phase 2: Core Layers

- [ ] Convolutional layers (Conv1D, Conv2D)
- [ ] Pooling layers
- [ ] Dropout layer
- [ ] Batch normalization
- [ ] Flatten, Reshape layers
- [ ] Update examples to use new layers

### Phase 3: Training Enhancements

- [ ] Validation split
- [ ] Early stopping callback
- [ ] Model checkpoint callback
- [ ] Learning rate scheduler
- [ ] Data augmentation utilities
- [ ] CSV logger, Progress bar

### Phase 4: Advanced Layers

- [ ] Recurrent layers (LSTM, GRU)
- [ ] Attention mechanisms
- [ ] Embedding layer
- [ ] Advanced normalization (Layer, Group)
- [ ] Merge layers (Concatenate, Add, etc.)

### Phase 5: Model API

- [ ] Functional API (Input, Model with inputs/outputs)
- [ ] Multi-input/multi-output support
- [ ] Model.summary()
- [ ] Layer inspection utilities
- [ ] Model cloning

### Phase 6: Advanced Features

- [ ] Pre-trained model loading
- [ ] Transfer learning examples
- [ ] Model visualization
- [ ] Cross-validation utilities
- [ ] Hyperparameter tuning helpers

### Phase 7: Optimization

- [ ] Memory optimization
- [ ] Performance benchmarking
- [ ] Lazy evaluation where possible

### Phase 8: Polish & Release

- [ ] Complete documentation
- [ ] Migration guide
- [ ] Performance comparison with v1
- [ ] v2.0.0 release

## Resources & Dependencies

### Team
- 2-3 core maintainers
- Community contributors for specific features
- Technical writer for documentation

### Infrastructure

- CI/CD for all target runtimes (already set up with GitHub Actions)
- Performance benchmarking suite
- Documentation hosting (done with jsr.io https://jsr.io/@am/neuralnetwork/doc based on jsdoc comments)
- Model zoo hosting (for pre-trained models)

### External Dependencies

- Remain zero runtime dependencies
- Dev dependencies: Testing framework, bundler, docs generator

## Risk Assessment

### Technical Risks
- **Complexity**: Adding many features may hurt maintainability
  - *Mitigation*: Modular architecture, comprehensive tests, clear code guidelines

### Project Risks
- **Scope creep**: Too many features may delay release
  - *Mitigation*: Strict phase adherence, MVP focus, iterative releases

- **Breaking changes**: v2 incompatibility may lose users
  - *Mitigation*: Compatibility layer, clear migration guide, deprecation warnings

- **Competition**: TensorFlow.js, Brain.js already exist
  - *Mitigation*: Focus on simplicity, education, and developer experience

## Future Considerations (Post-v2)

- Model quantization for mobile deployment
- Automatic differentiation improvements
- Neural architecture search
- Federated learning support
- ONNX import/export
- Integration with popular frameworks
- Native mobile runtime (React Native, Flutter)
- Edge deployment optimization

## Conclusion

Version 2.0 represents a significant evolution of `@am/neuralnetwork` from an educational library to a production-capable deep learning framework. By maintaining core principles of simplicity and cross-runtime compatibility while adding essential features like CNNs, RNNs, callbacks, and proper tensor management, v2 will serve a much broader audience while remaining accessible to learners.

The phased approach ensures steady progress while allowing for community feedback and course corrections. Success will be measured not just in features shipped, but in developer satisfaction and real-world adoption.
